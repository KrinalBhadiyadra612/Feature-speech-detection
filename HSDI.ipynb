{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45713c1e-0452-4e34-a71c-2a482385cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, precision_score, accuracy_score, mean_absolute_error, mean_squared_error, classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Bidirectional, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04ec24b4-9d9a-402d-ba3a-a240909b4e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@user nice new signage. Are you not concerned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A woman who you fucked multiple times saying y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@user @user real talk do you have eyes or were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>your girlfriend lookin at me like a groupie in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hysterical woman like @user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                   post_description\n",
       "0        1  @user nice new signage. Are you not concerned ...\n",
       "1        2  A woman who you fucked multiple times saying y...\n",
       "2        3  @user @user real talk do you have eyes or were...\n",
       "3        4  your girlfriend lookin at me like a groupie in...\n",
       "4        5                        Hysterical woman like @user"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = './structured_posts.csv'\n",
    "structured_df = pd.read_csv(csv_path)\n",
    "structured_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fdf1e820-36e6-4514-90f8-8f4f0cd3b747",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2612 unique hate terms from 28 files.\n",
      "       hate_word\n",
      "0        nussija\n",
      "1    ejaculation\n",
      "2      anilingus\n",
      "3      orospudan\n",
      "4  splooge moose\n"
     ]
    }
   ],
   "source": [
    "lexicon_path = './hatelexicons'\n",
    "hate_words = set()\n",
    "\n",
    "for filename in os.listdir(lexicon_path):\n",
    "    file_path = os.path.join(lexicon_path, filename)\n",
    "    \n",
    "    if filename.startswith('.'):\n",
    "        continue\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        words = {line.strip().lower() for line in f if line.strip()}\n",
    "        hate_words.update(words)\n",
    "\n",
    "print(f\"Loaded {len(hate_words)} unique hate terms from {len(os.listdir(lexicon_path))} files.\")\n",
    "hate_df = pd.DataFrame(list(hate_words), columns=[\"hate_word\"])\n",
    "print(hate_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17f6f671-c20d-4153-91fa-f8f22e13d838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_description</th>\n",
       "      <th>cleaned_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user nice new signage. Are you not concerned ...</td>\n",
       "      <td>user nice new signage are you not concerned by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman who you fucked multiple times saying y...</td>\n",
       "      <td>a woman who you fucked multiple times saying y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user real talk do you have eyes or were...</td>\n",
       "      <td>user user real talk do you have eyes or were t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your girlfriend lookin at me like a groupie in...</td>\n",
       "      <td>your girlfriend lookin at me like a groupie in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hysterical woman like @user</td>\n",
       "      <td>hysterical woman like user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    post_description  \\\n",
       "0  @user nice new signage. Are you not concerned ...   \n",
       "1  A woman who you fucked multiple times saying y...   \n",
       "2  @user @user real talk do you have eyes or were...   \n",
       "3  your girlfriend lookin at me like a groupie in...   \n",
       "4                        Hysterical woman like @user   \n",
       "\n",
       "                                        cleaned_post  \n",
       "0  user nice new signage are you not concerned by...  \n",
       "1  a woman who you fucked multiple times saying y...  \n",
       "2  user user real talk do you have eyes or were t...  \n",
       "3  your girlfriend lookin at me like a groupie in...  \n",
       "4                         hysterical woman like user  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  \n",
    "        u\"\\U0001F300-\\U0001F5FF\" \n",
    "        u\"\\U0001F680-\\U0001F6FF\" \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "        u\"\\U00002500-\\U00002BEF\" \n",
    "        u\"\\U00002702-\\U000027B0\" \n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()                          \n",
    "    text = remove_emojis(text)                   \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)        \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()    \n",
    "    return text\n",
    "\n",
    "structured_df['cleaned_post'] = structured_df['post_description'].apply(preprocess_text)\n",
    "structured_df[['post_description', 'cleaned_post']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae80aab0-f726-42f9-9adc-75793327fe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    6120\n",
      "1    2873\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def label_hate_speech(text, hate_words):\n",
    "    tokens = text.split()\n",
    "    return int(any(token in hate_words for token in tokens))\n",
    "\n",
    "structured_df['label'] = structured_df['cleaned_post'].apply(\n",
    "    lambda x: label_hate_speech(x, hate_words)\n",
    ")\n",
    "print(structured_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c0ce2d3-bdf5-4494-a14a-d3ca48252e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000) #max_features=1000\n",
    "X = vectorizer.fit_transform(structured_df['cleaned_post'])\n",
    "y = structured_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e575db48-38e2-4dfd-8312-ade63055c144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>account</th>\n",
       "      <th>accused</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>yesallmen</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>youre</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.362155</td>\n",
       "      <td>0.261531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  about  abuse  accept  access  account  accused  across  act  action  \\\n",
       "0   0.0    0.0    0.0     0.0     0.0      0.0      0.0     0.0  0.0     0.0   \n",
       "1   0.0    0.0    0.0     0.0     0.0      0.0      0.0     0.0  0.0     0.0   \n",
       "2   0.0    0.0    0.0     0.0     0.0      0.0      0.0     0.0  0.0     0.0   \n",
       "3   0.0    0.0    0.0     0.0     0.0      0.0      0.0     0.0  0.0     0.0   \n",
       "4   0.0    0.0    0.0     0.0     0.0      0.0      0.0     0.0  0.0     0.0   \n",
       "\n",
       "   ...  yesallmen  yet        yo       you  youll  young      your  youre  \\\n",
       "0  ...        0.0  0.0  0.000000  0.378662    0.0    0.0  0.000000    0.0   \n",
       "1  ...        0.0  0.0  0.362155  0.261531    0.0    0.0  0.000000    0.0   \n",
       "2  ...        0.0  0.0  0.000000  0.147510    0.0    0.0  0.000000    0.0   \n",
       "3  ...        0.0  0.0  0.000000  0.000000    0.0    0.0  0.302445    0.0   \n",
       "4  ...        0.0  0.0  0.000000  0.000000    0.0    0.0  0.000000    0.0   \n",
       "\n",
       "   yourself  youve  \n",
       "0       0.0    0.0  \n",
       "1       0.0    0.0  \n",
       "2       0.0    0.0  \n",
       "3       0.0    0.0  \n",
       "4       0.0    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "vectorized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf433b9-ed7e-4e54-95d1-bca41ae94ff0",
   "metadata": {},
   "source": [
    "#Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af3e8796-4465-442a-94e4-187d92a7ac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      1217\n",
      "           1       0.87      0.90      0.89       582\n",
      "\n",
      "    accuracy                           0.93      1799\n",
      "   macro avg       0.91      0.92      0.92      1799\n",
      "weighted avg       0.93      0.93      0.93      1799\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1141   76]\n",
      " [  58  524]]\n",
      "\n",
      "Additional Metrics:\n",
      "AUC/ROC: 0.9720\n",
      "Precision: 0.8733\n",
      "Accuracy: 0.9255\n",
      "MAE: 0.1808\n",
      "MSE: 0.0678\n",
      "RMSE: 0.2605\n",
      "MAPE: 115501987223.76%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, structured_df['label'], test_size=0.2, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred = nb_model.predict(X_test)\n",
    "y_pred_prob = nb_model.predict_proba(X_test)[:, 1] \n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "roc_nb = roc_auc_score(y_test, y_pred_prob)  \n",
    "precision_nb = precision_score(y_test, y_pred)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred)\n",
    "mae_nb = mean_absolute_error(y_test, y_pred_prob)\n",
    "mse_nb = mean_squared_error(y_test, y_pred_prob)\n",
    "rmse_nb = np.sqrt(mse_nb)\n",
    "epsilon = 1e-10  \n",
    "mape_nb = np.mean(np.abs((y_test - y_pred_prob) / (y_test + epsilon))) * 100\n",
    "\n",
    "print(\"\\nAdditional Metrics:\")\n",
    "print(f\"AUC/ROC: {roc_nb:.4f}\")\n",
    "print(f\"Precision: {precision_nb:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_nb:.4f}\")\n",
    "print(f\"MAE: {mae_nb:.4f}\")\n",
    "print(f\"MSE: {mse_nb:.4f}\")\n",
    "print(f\"RMSE: {rmse_nb:.4f}\")\n",
    "print(f\"MAPE: {mape_nb:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c46146c7-92a5-4e9e-aa33-2522e831a45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.12/site-packages (3.9.0)\n",
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.19.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.51.0)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.5.0)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.12/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras) (0.14.1)\n",
      "Requirement already satisfied: ml-dtypes in /opt/anaconda3/lib/python3.12/site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras tensorflow transformers datasets torch scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f81d3-dcfd-4392-8dba-69c9b25022a0",
   "metadata": {},
   "source": [
    "# BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f84a204e-eb2b-4914-b375-eee998ec535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(structured_df['cleaned_post'])\n",
    "sequences = tokenizer.texts_to_sequences(structured_df['cleaned_post'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, structured_df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f160f42-cd8f-4bc3-8771-2e3a078b0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "with open('./glove.6B/glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = vector\n",
    "\n",
    "embedding_dim = 100\n",
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((MAX_NUM_WORDS, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "43eda38e-3db5-4b2e-a6d1-84b02ba5f672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.7594 - loss: 0.4762 - val_accuracy: 0.9250 - val_loss: 0.2015\n",
      "Epoch 2/6\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9330 - loss: 0.1887 - val_accuracy: 0.9375 - val_loss: 0.1782\n",
      "Epoch 3/6\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9574 - loss: 0.1294 - val_accuracy: 0.9639 - val_loss: 0.1020\n",
      "Epoch 4/6\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9639 - loss: 0.1114 - val_accuracy: 0.9625 - val_loss: 0.1290\n",
      "Epoch 5/6\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.9763 - loss: 0.0730 - val_accuracy: 0.9806 - val_loss: 0.0756\n",
      "Epoch 6/6\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.9838 - loss: 0.0538 - val_accuracy: 0.9778 - val_loss: 0.0736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30174c830>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Embedding(MAX_NUM_WORDS, embedding_dim, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=6, batch_size=32, validation_split=0.1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de294622-9aed-4ab4-b3ce-3dc413036bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "AUC/ROC: 0.9936\n",
      "Precision: 0.9500\n",
      "Accuracy: 0.9767\n",
      "MAE: 0.0367\n",
      "MSE: 0.0203\n",
      "RMSE: 0.1424\n",
      "MAPE: inf%\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test).ravel()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "roc = roc_auc_score(y_test, y_pred_prob)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred_prob)\n",
    "mse = mean_squared_error(y_test, y_pred_prob)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = np.mean(np.abs((y_test - y_pred_prob) / y_test)) * 100\n",
    "\n",
    "print(f\"AUC/ROC: {roc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85f705-9988-449b-bead-0bc2689c1c9d",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f3a730c-1b9e-4817-973e-6cec0cff5ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics\n",
      "AUC/ROC: 0.6333\n",
      "Precision: 0.2000\n",
      "Accuracy: 0.6748\n",
      "MAE: 0.4250\n",
      "MSE: 0.2120\n",
      "RMSE: 0.4605\n",
      "MAPE: 210213086228.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "base_model = LinearSVC(random_state=42)\n",
    "svm_model = CalibratedClassifierCV(base_model, cv=5)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob_svm = svm_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_svm = (y_pred_prob_svm > 0.5).astype(int)\n",
    "\n",
    "roc_svm = roc_auc_score(y_test, y_pred_prob_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "mae_svm = mean_absolute_error(y_test, y_pred_prob_svm)\n",
    "mse_svm = mean_squared_error(y_test, y_pred_prob_svm)\n",
    "rmse_svm = np.sqrt(mse_svm)\n",
    "epsilon = 1e-10\n",
    "mape_svm = np.mean(np.abs((y_test - y_pred_prob_svm) / (y_test + epsilon))) * 100\n",
    "\n",
    "print(\"SVM Metrics\")\n",
    "metrics_svm = {\n",
    "    \"AUC/ROC\": roc_svm,\n",
    "    \"Precision\": precision_svm,\n",
    "    \"Accuracy\": accuracy_svm,\n",
    "    \"MAE\": mae_svm,\n",
    "    \"MSE\": mse_svm,\n",
    "    \"RMSE\": rmse_svm,\n",
    "    \"MAPE\": mape_svm\n",
    "}\n",
    "for metric, value in metrics_svm.items():\n",
    "    print(f\"{metric}: {value:.2f}%\" if metric == \"MAPE\" else f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d0725-6e33-4252-b4d3-20680e6b877f",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2edd6504-389f-49c1-9651-36ba18214391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.4258 - val_accuracy: 0.9389 - val_loss: 0.1577\n",
      "Epoch 2/5\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9559 - loss: 0.1352 - val_accuracy: 0.9556 - val_loss: 0.1316\n",
      "Epoch 3/5\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9823 - loss: 0.0624 - val_accuracy: 0.9639 - val_loss: 0.1001\n",
      "Epoch 4/5\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0383 - val_accuracy: 0.9667 - val_loss: 0.1109\n",
      "Epoch 5/5\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0145 - val_accuracy: 0.9681 - val_loss: 0.1168\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "CNN Metrics\n",
      "AUC/ROC: 0.9938\n",
      "Precision: 0.9615\n",
      "Accuracy: 0.9700\n",
      "MAE: 0.0352\n",
      "MSE: 0.0232\n",
      "RMSE: 0.1522\n",
      "MAPE: 16832950862.10%\n"
     ]
    }
   ],
   "source": [
    "cnn_model = Sequential([\n",
    "    Embedding(input_dim=MAX_NUM_WORDS, \n",
    "              output_dim=embedding_dim, \n",
    "              weights=[embedding_matrix], \n",
    "              input_length=MAX_SEQUENCE_LENGTH, \n",
    "              trainable=False),\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
    "cnn_model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
    "y_pred_prob_cnn = cnn_model.predict(X_test).ravel()\n",
    "y_pred_cnn = (y_pred_prob_cnn > 0.5).astype(int)\n",
    "\n",
    "roc_cnn = roc_auc_score(y_test, y_pred_prob_cnn)\n",
    "precision_cnn = precision_score(y_test, y_pred_cnn)\n",
    "accuracy_cnn = accuracy_score(y_test, y_pred_cnn)\n",
    "mae_cnn = mean_absolute_error(y_test, y_pred_prob_cnn)\n",
    "mse_cnn = mean_squared_error(y_test, y_pred_prob_cnn)\n",
    "rmse_cnn = np.sqrt(mse_cnn)\n",
    "mape_cnn = np.mean(np.abs((y_test - y_pred_prob_cnn) / (y_test + epsilon))) * 100\n",
    "\n",
    "print(\"CNN Metrics\")\n",
    "print(\"AUC/ROC: {:.4f}\".format(roc_cnn))\n",
    "print(\"Precision: {:.4f}\".format(precision_cnn))\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_cnn))\n",
    "print(\"MAE: {:.4f}\".format(mae_cnn))\n",
    "print(\"MSE: {:.4f}\".format(mse_cnn))\n",
    "print(\"RMSE: {:.4f}\".format(rmse_cnn))\n",
    "print(\"MAPE: {:.2f}%\".format(mape_cnn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b54aba-5ce6-4617-bd6e-ab6ffe8cb04e",
   "metadata": {},
   "source": [
    "## Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9b68b9eb-0b98-4f59-8c5f-ba40d6ce5a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics \n",
      "AUC/ROC: 0.7226\n",
      "Precision: 0.5892\n",
      "Accuracy: 0.6948\n",
      "MAE: 0.3932\n",
      "MSE: 0.1923\n",
      "RMSE: 0.4385\n",
      "MAPE: 199760978340.63%\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf = (y_pred_prob_rf > 0.5).astype(int)\n",
    "\n",
    "roc_rf = roc_auc_score(y_test, y_pred_prob_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_prob_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_prob_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "epsilon = 1e-10  \n",
    "mape_rf = np.mean(np.abs((y_test - y_pred_prob_rf) / (y_test + epsilon))) * 100\n",
    "\n",
    "print(\"Random Forest Metrics \")\n",
    "print(\"AUC/ROC: {:.4f}\".format(roc_rf))\n",
    "print(\"Precision: {:.4f}\".format(precision_rf))\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_rf))\n",
    "print(\"MAE: {:.4f}\".format(mae_rf))\n",
    "print(\"MSE: {:.4f}\".format(mse_rf))\n",
    "print(\"RMSE: {:.4f}\".format(rmse_rf))\n",
    "print(\"MAPE: {:.2f}%\".format(mape_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8b7cf45-35d8-4bd6-a9ac-9797f6765ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation Summary:\n",
      "\n",
      "               AUC/ROC  Precision  Accuracy     MAE     MSE    RMSE  \\\n",
      "Naive Bayes     0.9720     0.8733    0.9255  0.1808  0.0678  0.2605   \n",
      "BiLSTM          0.9936     0.9500    0.9767  0.0367  0.0203  0.1424   \n",
      "SVM             0.6333     0.2000    0.6748  0.4250  0.2120  0.4605   \n",
      "CNN             0.9938     0.9615    0.9700  0.0352  0.0232  0.1522   \n",
      "Random Forest   0.7226     0.5892    0.6948  0.3932  0.1923  0.4385   \n",
      "\n",
      "                           MAPE  \n",
      "Naive Bayes    115501987223.76%  \n",
      "BiLSTM                     inf%  \n",
      "SVM            210213086228.88%  \n",
      "CNN             16832950862.10%  \n",
      "Random Forest  199760978340.63%  \n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-10\n",
    "metrics_summary = {\n",
    "    \"Naive Bayes\": {\n",
    "        \"AUC/ROC\": roc_nb,\n",
    "        \"Precision\": precision_nb,\n",
    "        \"Accuracy\": accuracy_nb,\n",
    "        \"MAE\": mae_nb,\n",
    "        \"MSE\": mse_nb,\n",
    "        \"RMSE\": rmse_nb,\n",
    "        \"MAPE\": mape_nb\n",
    "    },\n",
    "    \"BiLSTM\": {\n",
    "        \"AUC/ROC\": roc,\n",
    "        \"Precision\": precision,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE\": mape\n",
    "    },\n",
    "    \"SVM\": metrics_svm,\n",
    "     \"CNN\": {\n",
    "        \"AUC/ROC\": roc_cnn,\n",
    "        \"Precision\": precision_cnn,\n",
    "        \"Accuracy\": accuracy_cnn,\n",
    "        \"MAE\": mae_cnn,\n",
    "        \"MSE\": mse_cnn,\n",
    "        \"RMSE\": rmse_cnn,\n",
    "        \"MAPE\": mape_cnn\n",
    "    },\n",
    "     \"Random Forest\": {\n",
    "        \"AUC/ROC\": roc_rf,\n",
    "        \"Precision\": precision_rf,\n",
    "        \"Accuracy\": accuracy_rf,\n",
    "        \"MAE\": mae_rf,\n",
    "        \"MSE\": mse_rf,\n",
    "        \"RMSE\": rmse_rf,\n",
    "        \"MAPE\": mape_rf\n",
    "    },\n",
    "}\n",
    "summary_df = pd.DataFrame(metrics_summary).T \n",
    "\n",
    "summary_df[\"MAPE\"] = summary_df[\"MAPE\"].apply(lambda x: f\"{x:.2f}%\")\n",
    "summary_df = summary_df.round(4)\n",
    "\n",
    "print(\"Final Model Evaluation Summary:\\n\")\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64de4de4-bd0d-483d-9812-40a28a59fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('naive_bayes_model.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_model, f)\n",
    "\n",
    "with open('svm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(svm_model, f)\n",
    "\n",
    "with open('cnn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(cnn_model, f)\n",
    "\n",
    "with open('bilstm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4ad6936-6f90-48f8-8200-523b221c3ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d3f084c-27ba-41a1-8cd9-3f760d8b0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
    " pickle.dump(vectorizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ace80d3c-a99d-4b6b-88c4-dbc6c76c1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be30665b-b0c9-4a1f-bc65-b2da0ddf5e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
